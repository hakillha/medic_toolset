{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_picked: 316\n",
      "all_picked: 229\n",
      "WARNING:tensorflow:From ../../../fw_dependent/tf/model/tf_layers.py:52: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../../fw_dependent/tf/model/ASEUNet.py:95: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../../fw_dependent/tf/model/ASEUNet.py:37: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.AveragePooling2D instead.\n",
      "WARNING:tensorflow:From ../../../fw_dependent/tf/model/ASEUNet.py:39: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /rdfs/fast/home/sunyingge/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From ../../../fw_dependent/tf/model/ASEUNet.py:98: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From ../../../fw_dependent/tf/model/ASEUNet.py:4: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../../fw_dependent/tf/model/ASEUNet.py:13: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../../fw_dependent/tf/model/ASEUNet.py:77: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "WARNING:tensorflow:From /rdfs/fast/home/sunyingge/anaconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /rdfs/fast/home/sunyingge/data/models/workdir_0522/SEResUNet_0526_01/epoch_2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/545 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32901b4240>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32546edfd0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import argparse, logging, os, sys, time\n",
    "import cv2, pickle, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from os.path import join as pj\n",
    "from tqdm import tqdm\n",
    "\n",
    "# When the TF module is large enough create a seperate folder for it\n",
    "# TODO: Change working directory to point to folder of this script\n",
    "sys.path.insert(0, \"../../..\") \n",
    "# from fast.cf_mod.misc.data_tools import BaseDataset, paths_for_dataset\n",
    "from fast.cf_mod.misc.data_tools import BaseDataset\n",
    "from fast.cf_mod.misc.utils import get_infos\n",
    "from fast.cf_mod.misc.my_metrics import dice_coef_pat\n",
    "# TODO: unify the process of building models\n",
    "from fw_dependent.tf.model.tf_layers import tf_model\n",
    "from fw_neutral.utils.data_proc import paths_from_data, im_normalize, preprocess\n",
    "from fw_neutral.utils.config import Config\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        \"\"\"\n",
    "        You need to be careful with resuming while also changing the batch size \n",
    "        with this script since it would change how many steps to take to drop LR.\n",
    "        \n",
    "        \"eval\" mode: \n",
    "            \"--model_file\": Checkpoint file.\n",
    "            \"--testset_dir\"\n",
    "            \"--pkl_dir\": Output.\n",
    "        \"\"\")\n",
    "    parser.add_argument(\"mode\", choices=[\"train\", \"eval\"])\n",
    "    parser.add_argument(\"gpu\", help=\"Choose GPU.\")\n",
    "    parser.add_argument(\"config\", help=\"Config file.\")\n",
    "    \n",
    "    # Training mode related\n",
    "    parser.add_argument(\"-o\", \"--output_dir\",\n",
    "        help=\"\"\"You only need to provide a prefix which will be automatically be \n",
    "            complemented by time to keep things distincive easily. This will be ignored\n",
    "            when resuming from a checkpoint.\"\"\",\n",
    "        default=\"/rdfs/fast/home/sunyingge/data/models/workdir_0522/SEResUNET_\")\n",
    "    parser.add_argument(\"--train_dir\", help=\"Training set directory.\",\n",
    "        # default=\"/rdfs/fast/home/sunyingge/data/COV_19/prced_0512/Train_0519/\",\n",
    "        default=\"/rdfs/fast/home/sunyingge/data/COV_19/prced_0512/Train_0526/\",\n",
    "        )\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
    "        help=\"Provided here to enable easy overwritting (not supported yet).\")\n",
    "    parser.add_argument(\"--resume\", help=\"Checkpoint file to resume from.\",\n",
    "        )\n",
    "    parser.add_argument(\"--max_to_keep\", default=30, help=\"Max number of checkpoint files to keep.\")\n",
    "    parser.add_argument(\"--num_retry\", default=60)\n",
    "    parser.add_argument(\"--retry_waittime\", default=120, help=\"In seconds.\")\n",
    "    parser.add_argument(\"--eval_while_train\", action=\"store_true\", default=True,\n",
    "        help=\"\"\"Need to provide \"--testset_dir\" for this.\"\"\")\n",
    "\n",
    "    # Eval mode related\n",
    "    parser.add_argument(\"--testset_dir\", nargs='+',\n",
    "        default=[\"/rdfs/fast/home/sunyingge/data/COV_19/0508/TestSet/0519/normal_pneu_datasets\",\n",
    "        \"/rdfs/fast/home/sunyingge/data/COV_19/0508/TestSet/0519/covid_pneu_datasets\"]\n",
    "        )\n",
    "    parser.add_argument(\"--model_file\",\n",
    "#         default=\"/rdfs/fast/home/sunyingge/data/models/workdir_0522/SEResUNET_0525_2051_19/epoch_9.ckpt\"\n",
    "        default=\"/rdfs/fast/home/sunyingge/data/models/workdir_0522/SEResUNet_0526_01/epoch_2.ckpt\"\n",
    "        )\n",
    "    parser.add_argument(\"--pkl_dir\",\n",
    "#         default=\"/rdfs/fast/home/sunyingge/data/models/workdir_0522/SEResUNET_0525_2051_19/epoch_9_res.pkl\",\n",
    "        default=\"/rdfs/fast/home/sunyingge/data/models/workdir_0522/SEResUNet_0526_01/epoch_2_res.pkl\"\n",
    "        )\n",
    "    parser.add_argument(\"--thickness_thres\", default=3.0)\n",
    "\n",
    "    parser.add_argument(\"--debug\", action=\"store_true\")\n",
    "\n",
    "#     return parser.parse_args()\n",
    "#     So that this works with jupyter\n",
    "    return parser.parse_args(args=[\n",
    "        \"eval\",\n",
    "        \"2\",\n",
    "        \"/rdfs/fast/home/sunyingge/data/models/workdir_0522/SEResUNet_0526_01/cfg.json\",\n",
    "#         \"/rdfs/fast/home/sunyingge/data/models/workdir_0522/SEResUNET_0525_2051_19/base.json\",\n",
    "    ])\n",
    "\n",
    "def ini_training_set(args, cfg):\n",
    "    print(\"==>>Training set: \")\n",
    "    # _, train_pos, _ = paths_for_dataset(args.train_dir,\n",
    "    #     flags=[\"train\"],\n",
    "    #     seed=999,\n",
    "    #     isprint=True)\n",
    "    train_paths  = paths_from_data(args.train_dir)\n",
    "    np.random.seed(999)\n",
    "    train_paths = np.random.permutation(train_paths).tolist()\n",
    "    print(\"++\"*30)\n",
    "    print(f\"Number of training samples: {len(train_paths)}\")\n",
    "    train_dataset = BaseDataset(train_paths, [], img_size=cfg.im_size, choice=\"all\",\n",
    "        image_key=\"im\", mask_key=\"mask\")\n",
    "    print(f\"train_dataset: {len(train_dataset)}\")\n",
    "    return train_dataset\n",
    "\n",
    "def train(sess, args, cfg):\n",
    "    train_dataset = ini_training_set(args, cfg)\n",
    "    num_batches = len(train_dataset) // cfg.batch_size\n",
    "    model = tf_model(args, cfg, num_batches)\n",
    "    if args.resume:\n",
    "        output_dir = os.path.dirname(args.resume)\n",
    "    else:\n",
    "        if os.path.exists(args.output_dir):\n",
    "            output_dir = args.output_dir\n",
    "        else:\n",
    "            output_dir = args.output_dir + time.strftime(\"%m%d_%H%M_%S\", time.localtime())\n",
    "        if os.path.exists(output_dir):\n",
    "            if not args.debug:\n",
    "                input(\"The output directory already exists, please wait a moment and restart...\")\n",
    "                # print(\"The output directory already exists, please wait a moment and restart...\")\n",
    "                # sys.exit()\n",
    "        else:\n",
    "            os.makedirs(output_dir)\n",
    "        if not os.path.exists(pj(output_dir, os.path.basename(args.config))):\n",
    "            shutil.copy(args.config, output_dir)\n",
    "    logging.basicConfig(level=logging.DEBUG,\n",
    "        format=\"%(asctime)s %(message)s\",\n",
    "        datefmt=\"%m-%d %H:%M\",\n",
    "        filename=pj(output_dir, \"training.log\"),\n",
    "        filemode=\"a\")\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    console.setFormatter(logging.Formatter(\"%(message)s\"))\n",
    "    logging.getLogger(\"\").addHandler(console)\n",
    "    saver = tf.train.Saver(max_to_keep=args.max_to_keep)\n",
    "    num_para = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "    logging.info(\"Total number of trainable parameters: {:.3}M.\\n\".format(float(num_para)/1e6))\n",
    "    if args.resume:\n",
    "        saver.restore(sess, args.resume)\n",
    "        # This needs to be changed if the naming rule changes\n",
    "        epoch = int((os.path.basename(args.resume).split('.')[0]).split('_')[-1])\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        epoch = 0\n",
    "    while epoch < cfg.max_epoch:\n",
    "        logging.info(f\"Epoch {epoch + 1}\\n\")\n",
    "        num_batches = 10 if args.debug else num_batches\n",
    "        for i in range(num_batches):\n",
    "            data_list = []\n",
    "            for j in range(i * cfg.batch_size, (i + 1) * cfg.batch_size):\n",
    "                im_ar, ann_ar = preprocess(train_dataset[j][0], train_dataset[j][1], cfg, True)\n",
    "                data_list.append((im_ar, ann_ar))\n",
    "                plt.imshow(ann_ar[:,:,0], cmap='gray')\n",
    "                plt.savefig('test02.jpg')\n",
    "                plt.imshow(im_ar[:,:,0], cmap='gray')\n",
    "                plt.savefig('test03.jpg')\n",
    "                input('as')\n",
    "            data_ar = np.array(data_list)\n",
    "            im_ar = data_ar[:,0,:,:,:]\n",
    "            if cfg.num_class == 1:\n",
    "                # to make it compatible with mutlicls label\n",
    "                ann_ar = data_ar[:,1,:,:,:] > 0 \n",
    "            elif cfg.loss == \"softmax\":\n",
    "                ann_ar = data_ar[:,1,:,:,0]\n",
    "            elif cfg.loss == \"sigmoid\":\n",
    "                ann_ar = np.repeat(data_ar[:,1,:,:,:], cfg.num_class + 1, -1)\n",
    "                all_cls_ids = np.ones(shape=ann_ar.shape)\n",
    "                for i in range(cfg.num_class + 1):\n",
    "                    all_cls_ids[...,i] = all_cls_ids[...,i] * i\n",
    "                ann_ar = ann_ar == all_cls_ids\n",
    "            ret_loss, ret_pred, _ = sess.run([model.loss, model.pred, model.optimizer],\n",
    "                feed_dict={model.input_im: im_ar, model.input_ann: ann_ar,})\n",
    "            # if i % 5 == 0:\n",
    "            logging.info(f\"Epoch progress: {i + 1} / {num_batches}, loss: {ret_loss}\")\n",
    "        for _ in range(args.num_retry):\n",
    "            try:\n",
    "                ckpt_dir = pj(output_dir, f\"epoch_{epoch + 1}.ckpt\")\n",
    "                saver.save(sess, ckpt_dir)\n",
    "                # a = np.random.uniform(size=1)#\n",
    "                # if a[0] < 0.9:#\n",
    "                #     raise Exception(\"Hi!\")#\n",
    "                break\n",
    "            except:\n",
    "                logging.warning(\"Failed to save checkpoint. Retry after 2 minutes...\")\n",
    "                time.sleep(args.retry_waittime)\n",
    "                # time.sleep(10)#\n",
    "        if args.eval_while_train:\n",
    "            evaluation(sess, args, cfg, model, ckpt_dir.replace(\".ckpt\", \"_res.pkl\"), log=True)\n",
    "        epoch += 1\n",
    "\n",
    "def show_dice(all_res, log=False):\n",
    "    stats = defaultdict(list)\n",
    "    for res in all_res:\n",
    "        if 'covid_pneu_datasets' in res[0]:\n",
    "            if res[2] >= args.thickness_thres:\n",
    "                stats['covid'].append(res[1])\n",
    "                stats['thick'].append(res[1])\n",
    "                stats['covid_thick'].append(res[1])\n",
    "            elif res[2] < args.thickness_thres:\n",
    "                stats['covid'].append(res[1])\n",
    "                stats['thin'].append(res[1])\n",
    "                stats['covid_thin'].append(res[1])\n",
    "        elif 'normal_pneu_datasets' in res[0]:\n",
    "            if res[2] >= args.thickness_thres:\n",
    "                stats['normal'].append(res[1])\n",
    "                stats['thick'].append(res[1])\n",
    "                stats['normal_thick'].append(res[1])\n",
    "            elif res[2] < args.thickness_thres:\n",
    "                stats['normal'].append(res[1])\n",
    "                stats['thin'].append(res[1])\n",
    "                stats['normal_thin'].append(res[1])\n",
    "    for key in stats:\n",
    "        if log:\n",
    "            logging.info(f\"{key}: {np.mean(np.array(stats[key]))}\")\n",
    "        else:\n",
    "            print(f\"{key}: {np.mean(np.array(stats[key]))}\")\n",
    "\n",
    "def evaluation(sess, args, cfg, model=None, pkl_dir=None, log=False):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            model: For eval during training.\n",
    "    \"\"\"\n",
    "    info_paths = []\n",
    "    for folder in args.testset_dir:\n",
    "        info_paths += get_infos(folder)\n",
    "    info_paths = sorted(info_paths, key=lambda info:info[0])\n",
    "    all_result = []\n",
    "    if not model:\n",
    "        model = tf_model(args, cfg)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, args.model_file)\n",
    "    else:\n",
    "        args.pkl_dir = pkl_dir\n",
    "    pbar = tqdm(total=len(info_paths))\n",
    "#     if os.path.exists(args.pkl_dir):\n",
    "#         input(\"Result file already exists. Press enter to \\\n",
    "#             continue and overwrite it when inference is done...\")\n",
    "    for num, info in enumerate(info_paths):\n",
    "        img_file, lab_file = info[0:2]\n",
    "        try:\n",
    "            img_ori,  lab_ori  = sitk.ReadImage(img_file, sitk.sitkFloat32), sitk.ReadImage(lab_file, sitk.sitkInt16)\n",
    "            img_arr,  lab_arr  = sitk.GetArrayFromImage(img_ori), sitk.GetArrayFromImage(lab_ori)\n",
    "            # This converts all positive pixels to 1 regardless of their exact class\n",
    "            lab_arr  = np.asarray(lab_arr > 0, dtype=np.uint8)\n",
    "        except:\n",
    "            continue\n",
    "        depth, ori_shape = img_arr.shape[0], img_arr.shape[1:]\n",
    "        spacing = img_ori.GetSpacing()\n",
    "        dis_arr = im_normalize(img_arr, cfg.eval[\"ct_interval\"][0], cfg.eval[\"ct_interval\"][1], \n",
    "            cfg.eval[\"norm_by_interval\"])\n",
    "        # dis_arr = resize3d(dis_arr, cfg.im_size, interpolation=cv2.INTER_LINEAR)\n",
    "        im_stack = []\n",
    "        topleft_list = [] if cfg.preprocess[\"cropping\"] else None\n",
    "        for i in range(dis_arr.shape[0]):\n",
    "            res = preprocess(dis_arr[i,...], None, cfg, False)\n",
    "#             plt.imshow(res[:,:,-1], cmap='gray')\n",
    "#             plt.imshow(res[1][:,:,-1], cmap='gray')\n",
    "#             plt.savefig('test.jpg')\n",
    "#             input('hi')\n",
    "            if cfg.preprocess[\"cropping\"]:\n",
    "                im_stack.append(res[0])\n",
    "                topleft_list.append(res[1])\n",
    "            elif cfg.preprocess[\"resize\"]:\n",
    "                im_stack.append(res)\n",
    "        dis_arr = np.array(im_stack)\n",
    "        \n",
    "        pred_ = []\n",
    "        segs = cfg.batch_size\n",
    "        assert isinstance(segs, int) and (segs>0) & (segs<70), \"Please\" \n",
    "        step = depth//segs + 1 if depth%segs != 0 else depth//segs\n",
    "        for ii in range(step):\n",
    "            if ii != step-1:\n",
    "                pp = sess.run(model.pred, feed_dict={model.input_im: dis_arr[ii*segs:(ii+1)*segs, ...]}) #[0]\n",
    "            else:\n",
    "                pp = sess.run(model.pred, feed_dict={model.input_im: dis_arr[ii*segs:, ...]}) #[0]\n",
    "            pp = 1/ (1 + np.exp(-pp)) # this only works for single class\n",
    "            pred_.append(pp)\n",
    "        dis_prd = np.concatenate(pred_, axis=0)\n",
    "        # add the og version in\n",
    "        if cfg.num_class == 1:\n",
    "            dis_prd = dis_prd > 0.5\n",
    "        else:\n",
    "            if \"normal_pneu\" in img_file:\n",
    "                cls_id = 2\n",
    "            elif \"covid_pneu\" in img_file:\n",
    "                cls_id = 1\n",
    "            dis_prd = np.argmax(dis_prd, -1) == cls_id\n",
    "#         print(dis_prd.shape)\n",
    "#         for i in range(dis_prd.shape[0]):\n",
    "#             print(np.sum(dis_prd[i,:,:,0]))\n",
    "        # dis_prd = resize3d(dis_prd.astype(np.uint8), ori_shape, interpolation=cv2.INTER_NEAREST)\n",
    "        # insert postprocessing here\n",
    "        # dis_prd = np.array([postprocess(dis_prd[i,...], cfg, topleft_list) for i in range(dis_prd.shape[0])])\n",
    "        pred_stack = []\n",
    "        for i in range(dis_prd.shape[0]):\n",
    "            if cfg.preprocess[\"cropping\"]:\n",
    "                padded_res = np.zeros(shape=ori_shape[::-1])\n",
    "                padded_res[topleft_list[i][1]:topleft_list[i][1] + cfg.im_size[0],topleft_list[i][0]:topleft_list[i][0] + cfg.im_size[1]] = dis_prd[i,:,:,0]\n",
    "                if np.sum(padded_res):\n",
    "                    plt.imshow(padded_res, cmap='gray')\n",
    "#                     plt.savefig('test01.jpg')\n",
    "                    plt.show()\n",
    "                    input('hi')\n",
    "                pred_stack.append(padded_res)\n",
    "            elif cfg.preprocess[\"resize\"]:\n",
    "                resized_res = cv2.resize(dis_prd[i,...].astype(np.float32), ori_shape[::-1], interpolation=cv2.INTER_NEAREST)\n",
    "                pred_stack.append(resized_res)\n",
    "#                 plt.imshow(resized_res, cmap='gray')\n",
    "# #                 plt.show()\n",
    "#                 plt.savefig('test01.jpg')\n",
    "#                 input('hi')\n",
    "        dis_prd = np.array(pred_stack)\n",
    "        score = dice_coef_pat(dis_prd, lab_arr)\n",
    "        if score < 0.3:\n",
    "            if log:\n",
    "                logging.info(os.path.dirname(lab_file))\n",
    "                logging.info(score)\n",
    "            else:\n",
    "                print(os.path.dirname(lab_file))\n",
    "                print(score)\n",
    "        all_result.append([img_file, score, round(spacing[-1], 1)])\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    pickle.dump(all_result, open(args.pkl_dir, \"bw\"))\n",
    "    show_dice(all_result, log=log)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "    cfg = Config()\n",
    "    cfg.load_from_json(args.config)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        train(sess, args, cfg)\n",
    "    elif args.mode == \"eval\":\n",
    "        evaluation(sess, args, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
